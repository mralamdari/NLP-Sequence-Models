{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP-Sequence-Models-Beginner.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "LNuQsXN63D_v"
      ],
      "authorship_tag": "ABX9TyPg7G4KQaFn2h0mg3smRldP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mr-alamdari/NLP-Sequence-Models-Beginner/blob/main/NLP_Sequence_Models_Beginner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "x0W9RKAVwSLZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import numpy\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U trax\n",
        "\n",
        "import trax\n",
        "\n",
        "import trax.fastmath.numpy as np\n",
        "\n",
        "from trax import layers as tl"
      ],
      "metadata": {
        "id": "uEwRNzEV2Ngn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7eebfd41-503d-4f3b-f45f-8a59f89ac305"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 637 kB 5.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 51.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 462 kB 43.9 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Practices**"
      ],
      "metadata": {
        "id": "LNuQsXN63D_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array(325)"
      ],
      "metadata": {
        "id": "6luyOIVn26zu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d499bc8-a42b-4524-a080-5f750641ae49"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "gjI-PK9B30Ft",
        "outputId": "4eb21844-bd09-499f-fa5f-99da8b5cfc23"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "DeviceArray(325, dtype=int32, weak_type=True)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dylyy-re37yA",
        "outputId": "b2c53127-578d-46b5-ac69-d655b53a7415"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "jaxlib.xla_extension.DeviceArray"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x):\n",
        "  return 3 * x**2 - 32"
      ],
      "metadata": {
        "id": "4K48Dkpu39Et"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_a = f(a)\n",
        "d_a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FjMFcbd4KIl",
        "outputId": "97f20d7a-49ea-496e-d34d-d834fa064261"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray(316843, dtype=int32, weak_type=True)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grad_f = trax.fastmath.grad(fun=f)"
      ],
      "metadata": {
        "id": "sBBER4nA4LZJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(grad_f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTb9EVLJ4Qyo",
        "outputId": "2c923f53-ffde-4664-bd61-52b3e35bee80"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "function"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tweet_to_tensor(tweet, vocab_dict, unk_token='__UNK__', verbose=False):\n",
        "\n",
        "    word_list = process_tweet(tweet)\n",
        "    tensor_l = []\n",
        "    unk_ID = vocab_dict[unk_token]\n",
        "\n",
        "    for word in word_list:\n",
        "        word_ID = vocab_dict[word] if word in vocab_dict else unk_ID\n",
        "        tensor_l.append(word_ID) \n",
        "    \n",
        "    return tensor_l"
      ],
      "metadata": {
        "id": "8BWLHvyW4jgO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Layer(object):\n",
        "    def __init__(self):\n",
        "        self.weights = None\n",
        "\n",
        "    def init(self, input_signature, random_key):\n",
        "        self.init_weights_and_state(input_signature, random_key)\n",
        "        return self.weights\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.forward(x)"
      ],
      "metadata": {
        "id": "FJOVqiZGOMiv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Relu(Layer):\n",
        "    def forward(self, x):\n",
        "        return np.maximum(x,0)"
      ],
      "metadata": {
        "id": "a0MXBVfTBehd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dense(Layer):\n",
        "\n",
        "    def __init__(self, n_units, init_stdev=0.1):\n",
        "        \n",
        "        self._n_units = n_units\n",
        "        self._init_stdev = init_stdev\n",
        "\n",
        "    def forward(self, x):\n",
        "        dense = np.dot(x, self.weights) \n",
        "        return dense\n",
        "\n",
        "    def init_weights_and_state(self, input_signature, random_key):\n",
        "        input_shape = input_signature.shape\n",
        "        w = self._init_stdev * trax.fastmath.random.normal(key = random_key, shape = (input_shape[-1], self._n_units))\n",
        "        self.weights = w\n",
        "        return self.weights"
      ],
      "metadata": {
        "id": "3OSjwW8wOny5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_embed = np.array([[1,2,3], [4,5,6]])\n",
        "\n",
        "display(np.mean(tmp_embed,axis=0))\n",
        "\n",
        "display(np.mean(tmp_embed,axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wtGgjaX_O0l8",
        "outputId": "c448cd0d-c823-4a36-832f-de0f904a554b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "DeviceArray([2.5, 3.5, 4.5], dtype=float32)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "DeviceArray([2., 5.], dtype=float32)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def classifier(vocab, embedding_dim=256, output_dim=2, mode='train'):\n",
        "    vocab_size=len(vocab)\n",
        "    embed_layer = tl.Embedding(vocab_size=vocab_size, d_feature=embedding_dim)\n",
        "    \n",
        "    mean_layer = tl.Mean(axis=1)\n",
        "    \n",
        "    dense_output_layer = tl.Dense(n_units = output_dim)\n",
        "\n",
        "    log_softmax_layer = tl.LogSoftmax()\n",
        "    \n",
        "    model = tl.Serial(\n",
        "      embed_layer,\n",
        "      mean_layer,\n",
        "      dense_output_layer,\n",
        "      log_softmax_layer\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "pNE0XrytPE39"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from trax.supervised import training\n",
        "\n",
        "def train_model(classifier, train_task, eval_task, n_steps, output_dir):\n",
        "    training_loop = training.Loop(\n",
        "                                classifier, # The learning model\n",
        "                                train_task, # The training task\n",
        "                                eval_task = eval_task, # The evaluation task\n",
        "                                output_dir = output_dir) # The output directory\n",
        "\n",
        "    training_loop.run(n_steps = n_steps)\n",
        "\n",
        "    return training_loop"
      ],
      "metadata": {
        "id": "ctgGCH56PfWq"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_accuracy(preds, y, y_weights):\n",
        "\n",
        "    is_pos =  preds[:, 1] > preds[:, 0] \n",
        "    is_pos_int = is_pos.astype(np.int32)\n",
        "    correct = is_pos_int == y\n",
        "    sum_weights = np.sum(y_weights)\n",
        "    correct_float = correct.astype(np.float32)\n",
        "    weighted_correct_float = correct_float * y_weights\n",
        "    weighted_num_correct = np.sum(weighted_correct_float)\n",
        "    accuracy = weighted_num_correct / sum_weights\n",
        "    return accuracy, weighted_num_correct, sum_weights"
      ],
      "metadata": {
        "id": "zCnOfHrAPp2v"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(generator, model):\n",
        "    accuracy = 0.\n",
        "    total_num_correct = 0\n",
        "    total_num_pred = 0\n",
        "    for batch in generator: \n",
        "        inputs = batch[0]\n",
        "        targets = batch[1]\n",
        "        example_weight = batch[2]\n",
        "        pred = model(inputs)\n",
        "        batch_accuracy, batch_num_correct, batch_num_pred = compute_accuracy(pred, targets, example_weight)\n",
        "        total_num_correct += batch_num_correct\n",
        "        total_num_pred += batch_num_pred\n",
        "    accuracy = total_num_correct / total_num_pred\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "cnXFrem6QKR9"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, Vocab, sentence):\n",
        "    inputs = np.array(tweet_to_tensor(sentence, vocab_dict=Vocab))\n",
        "    \n",
        "    inputs = inputs[None, :]  \n",
        "    \n",
        "    preds_probs = model(inputs)\n",
        "    \n",
        "    preds = int(preds_probs[0, 1] > preds_probs[0, 0])\n",
        "    \n",
        "    sentiment = \"negative\"\n",
        "    if preds == 1:\n",
        "        sentiment = 'positive'\n",
        "\n",
        "    return preds, sentiment"
      ],
      "metadata": {
        "id": "MIjhU65vQTy9"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jl82WYN_QlRS"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#N-Grams"
      ],
      "metadata": {
        "id": "-C85dZLc3NZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/amanjeetsahu/Natural-Language-Processing-Specialization/master/Natural%20Language%20Processing%20with%20Sequence%20Models/Week%202/shakespeare.png"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7perUho3QTo",
        "outputId": "42f9ccdb-0ffc-42af-ef10-6cc845254405"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-21 05:15:48--  https://raw.githubusercontent.com/amanjeetsahu/Natural-Language-Processing-Specialization/master/Natural%20Language%20Processing%20with%20Sequence%20Models/Week%202/shakespeare.png\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1713575 (1.6M) [image/png]\n",
            "Saving to: ‘shakespeare.png’\n",
            "\n",
            "shakespeare.png     100%[===================>]   1.63M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2022-04-21 05:15:48 (28.4 MB/s) - ‘shakespeare.png’ saved [1713575/1713575]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/amanjeetsahu/Natural-Language-Processing-Specialization/master/Natural%20Language%20Processing%20with%20Sequence%20Models/Week%202/data/1kinghenryiv.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWiA0ls43xEv",
        "outputId": "9ac39d76-5100-4da2-eac4-1a7c1ad3e061"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-21 05:15:49--  https://raw.githubusercontent.com/amanjeetsahu/Natural-Language-Processing-Specialization/master/Natural%20Language%20Processing%20with%20Sequence%20Models/Week%202/data/1kinghenryiv.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 145002 (142K) [text/plain]\n",
            "Saving to: ‘1kinghenryiv.txt’\n",
            "\n",
            "1kinghenryiv.txt    100%[===================>] 141.60K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2022-04-21 05:15:49 (6.20 MB/s) - ‘1kinghenryiv.txt’ saved [145002/145002]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lines = []\n",
        "with open('1kinghenryiv.txt', 'r') as files:\n",
        "  for line in files:\n",
        "      pure_line = line.strip()\n",
        "      if pure_line:\n",
        "          lines.append(pure_line)"
      ],
      "metadata": {
        "id": "bPugQJSz6Lgq"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines[0: 20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUgsTODZjMuW",
        "outputId": "58adb90a-bf85-43bc-b041-defc23ecda72"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1 KING HENRY IV',\n",
              " 'DRAMATIS PERSONAE',\n",
              " 'KING HENRY\\tthe Fourth. (KING HENRY IV:)',\n",
              " 'HENRY,',\n",
              " 'Prince of Wales\\t(PRINCE HENRY:)\\t|',\n",
              " '| sons of the King',\n",
              " 'JOHN of Lancaster\\t(LANCASTER:)\\t|',\n",
              " 'WESTMORELAND:',\n",
              " 'SIR WALTER BLUNT:',\n",
              " 'THOMAS PERCY\\tEarl of Worcester. (EARL OF WORCESTER:)',\n",
              " 'HENRY PERCY\\tEarl of Northumberland. (NORTHUMBERLAND:)',\n",
              " 'HENRY PERCY\\tsurnamed HOTSPUR, his son. (HOTSPUR:)',\n",
              " 'EDMUND MORTIMER\\tEarl of March. (MORTIMER:)',\n",
              " 'RICHARD SCROOP\\tArchbishop of York. (ARCHBISHOP OF YORK:)',\n",
              " 'ARCHIBALD\\tEarl of Douglas. (DOUGLAS:)',\n",
              " 'OWEN GLENDOWER:',\n",
              " 'SIR RICHARD VERNON\\t(VERNON:)',\n",
              " 'SIR JOHN FALSTAFF\\t(FALSTAFF:)',\n",
              " 'SIR MICHAEL\\ta friend to the Archbishop of York.',\n",
              " 'POINS:']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7rez21NojO77"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}